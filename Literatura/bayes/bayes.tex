\documentclass[12pt,a4paper]{amsart}
\usepackage[slovene]{babel}
%\usepackage[cp1250]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{url}
\usepackage[normalem]{ulem}
\usepackage[dvipsnames,usenames]{color}
\usepackage{graphicx}

% Oblika strani
\textwidth 15cm
\textheight 24cm
\oddsidemargin.5cm
\evensidemargin.5cm
\topmargin-5mm
\addtolength{\footskip}{10pt}
\pagestyle{plain}
\overfullrule=15pt % oznaci predlogo vrstico

% Ukazi za matematična okolja
\theoremstyle{definition} % tekst napisan pokončno
\newtheorem{definicija}{Definicija}[section]
\newtheorem{primer}[definicija]{Primer}
\newtheorem{opomba}[definicija]{Opomba}

\renewcommand\endprimer{\hfill$\diamondsuit$}


\theoremstyle{plain} % tekst napisan poševno
\newtheorem{lema}[definicija]{Lema}
\newtheorem{izrek}[definicija]{Izrek}
\newtheorem{trditev}[definicija]{Trditev}
\newtheorem{posledica}[definicija]{Posledica}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Bayesova teorija}
\author{Neža Kržan}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Bayesova statistika}
Bayesova statistika je statistična veja, ki nam s pomočjo matematičnih pristopov omogoča uporabo verjetnosti pri reševanju statističnih 
problemov. V svoje modele vključuje pogojno verjetnost, katero izračunamo z uporabo Bayesovega pravila. \\\\
Zlasti Bayesovo sklepanje razlaga verjetnost kot merilo verjetnosti ali zaupanja, ki ga lahko ima posameznik glede nastanka določenega dogodka. 
O nekem dogodku lahko že imamo predhodno prepričanje oziroma apriorno prepričanje, ki pa se lahko spremeni, ko se pojavijo novi dokazi. Bayesova 
statistika nam daje matematične modele za vključevanje naših apriornih prepričanj in dokazov za ustvarjenje novih prepričanj oziroma za 
pridobitev aposteriornega prepričanja, ki se lahko uporabi za kasnejše odločitve.\\\\
Bayesova analiza je standardna metoda za posodabljanje verjetnosti po opazovanju več dokazov, zato je zelo primerna za sintezo dokazov.
Vsakdo, ki mora presoditi o hipotezi, kot je "krivda" (vključno s preiskovalci pred sojenjem, sodniki, porotami), neformalno začne z nekim 
predhodnim prepričanjem o hipotezi in ga posodablja, ko se dokazi ponovno pojavijo. Včasih lahko obstajajo celo objektivni podatki, na katerih temelji 
predhodna verjetnost. Pri uporabi Bayesovega sklepanja morajo statistiki utemeljiti predhodne predpostavke, kadar je to mogoče, na primer z 
uporabo zunanjih podatkov; v nasprotnem primeru morajo uporabiti razpon vrednosti predpostavk in analizo občutljivosti, da preverijo zanesljivost rezultata 
glede na te vrednosti.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Beyesovo pravilo}
Bayesovo sklepanje temelji na Bayesovim pravilom, ki izraža verjetnost nekega dogodka z verjetnostjo dveh dogodkov in obrnejnje pogojne 
verjetnosti. Pogojna verjetnost predstavlja verjetnost dogodka, glede na drug dogodek.

\begin{definicija}
    Pogojna verjetnost dogodka H, glede na dogodek E, je
    \begin{equation}\label{eq:pogojna}
    P(H \lvert E) = \frac{P(H \cap E)}{P(E)},
    \end{equation}
    ob predpostavki, da je $P(E) > 0$.
\end{definicija}
    
Formula \eqref{eq:pogojna} pove, da je verjetnost dogodka H ob pogoju, da se je zgodil dogodek E, enaka razmerju verjetnosti, da se 
zgodita oba dogodka in verjetnosti, da se je zgodil dogodek E.
Potem pogojno verjetnost uporabimo še v števcu formule \eqref{eq:pogojna} in dobimo Bayesovo pravilo:
\begin{equation}\label{eq:bpravilo}
    P(H \lvert E) = \frac{P(E \lvert H) \times P(H)}{P(E)},
\end{equation}   
verjetnost dogodka E lahko še razpišemo in dobimo:
\begin{equation}\label{eq:b_pravilo}
    P(H \lvert E) = \frac{P(E \lvert H) \times P(H)}{P(E \lvert H)P(H) + P(E \lvert \neg H)P(\neg H)}.
\end{equation} \\\\
Obstaja še ena formulacija Bayesovega pravila, ki olajša izračune in je pogosto uporabljena pri Bayesovi analizi DNK dokazov:
\begin{equation}\label{eq:b_pravilo_DNK}
    \frac{P(H \lvert E)}{P(\neg H \lvert E)} = \frac{P(E \lvert H)}{P(E \lvert \neg H)} \times \frac{P(H)}{P(\neg H)}.
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Beyesovo posodabljanje}
Bayesovo pravilo se razlikuje od Bayesovega posodabljanja. Prvo je matematični izrek, drugo pa logična trditev, kako se sčasoma posodabljajo 
apriorne verjetnosti dokazov glede na novo zbrane dokaze oziroma prepričanja.\\\\
Bayesovo posodabljanje pravi:
\begin{trditev}
Če se dogodek E zgodi ob času $t_1 > t_0$, potem je $P_1(H) = P_0(H \lvert E)$.
\end{trditev}
Ob času $t_0$ dogodku H dodelimo verjetnost $P_0(H)$; to se imenuje predhodna verjetnost oziroma apriorna verjetnost. Ko se zgodi dogodek E 
ob času $t_1$, ki vpliva na naša prepričanja o dogodku H, Bayesovo posodabljanje pravi, da je potrebno apriorno verjetnost dogodka H v času $t_1$ 
enačiti z pogojno verjetnostjo dogodka H glede na dogodek E v času $t_0$. \\\\
Recimo, da je dogodek H neka hipoteza oziroma prepričanje o zločinu in dogodek E dokazi, zbrani za ta zložin. Pri Bayesovem posodabljanju je videti, 
kot da je dokaz E nesporno resničen. Z drugimi besedami, predpostavka je, da moramo imeti po zbiranju dokazov E stopnjo zaupanja v E enako 1, 
torej če so dokazi zbarni v času $t_1$, je $P_1(E)=1$. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Beyesova analiza}
V kazenskih zadevah želimo vedeti, ali je obtoženec kriv ali ne. Če imamo torej na voljo dokaz $E$, nas zanima pogojna verjetnost
\[
    P(kriv \lvert E),
\] 
pri čemer nam je lahko v pomoč Bayesovo pravilo. To v teoriji drži, čeprav je v praksi izračun verjetnostne krivde lahko
preveč zapleten. Ampak z Bayesovim pravilom lahko ocenimo verjetnosti vmesnih trditev oziroma dokazov, ki so ključnega pomena za ugotavljanje
obtoženčeve krivde. Najbolj pogosta uporaba Bayesovega pravila je pri ugotavljanju, ali je obtoženec vir sledi DNK-ja s kraja zločina.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Poenostavljena Bayesova analiza}
Naj bo:\\
$S$ \dots trditev, da je obtoženec vir sledi DNK s kraja zločina; \\
$M$ \dots trditev, da se obtoženčev DNK ujema z DNK-jem s kraja zločina; \\
$f$ \dots funkcija pogostosti ujemanja DNK z DNK-jem s kraja zločina. \\
Želimo vedeti, kakšna je verjetnost S glede na M, tj. $P(S \lvert M)$. \\\\
Bayesovo pravilo lahko uporabimo na naslednji način:
\[
    \frac{P(S \lvert M)}{P(\neg S \lvert M)} = \frac{P(M \lvert S)}{P(M \lvert \neg S)} \times \frac{P(S)}{P(\neg S)}.
\]\\
Verjetnosti $P(S)$ in $P(\neg S)$ je težko oceniti, ker ne vemo kakšna je množica osumljencev. Smiselno bi bilo, da zanju upoštevamo interval 
predhodnih verjetnosti in ocenimo njihov vpliv na verjetnost trditve $S$ in njene negacije. Nato moramo določiti vrednost $P(M \lvert S)$, ki 
je običajno enaka ena - če bi obtoženec dejansko pustil sledove, bi laboratorijske analize pokazale ujemanje(to imenujemo lažno 
negativni rezultat); to je sicer poenostavitev, saj se lahko zgodi, da analize ne pokažejo ujemanja, čeprav je obtoženec pustil sledi. 
Potrebujemo še verjetnost $P(M \lvert \neg S)$ (verjetnost, da se bo našlo ujemanje, če obtoženec ni vir sledi na kraju zločina). To je 
običajno enakovredno pogostosti ujemnja DNK-ja z DNK-jem s kraja zložina (tj. $f$); tudi to je poenostavitev, saj se lahko zgodi, da 
obtoženec nima enakega DNK profila, vendar so laboratorijske analize pokazale, da ga ima(to imenujemo lažno pozitivni rezultat).
Sledi:
\[
    \frac{P(S \lvert M)}{P(\neg S \lvert M)} = \frac{1}{f} \times \frac{P(S)}{P(\neg S)}.
\]\\
Ker poenostavljena Bayesova analiza ne upošteva možnosti lažno pozitivne in negativne laboratorijske analize si poglejmo še izpopolnjeno 
Bayesovo analizo.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Izpopolnjena Bayesova analiza}
Za upoštevanje možnosti laboratorijskih napak, bomo namesto $M$ uvedli spremenljivko $M_p$.\\
$M_p$ \dots poročano ujemanje laboratorijske analize; \\
$M_t$ \dots trditev, da obstaja dejansko ujemanje v DNK-ju;\\
$\neg M_t$ \dots trditev, da obstaja neujemanje v DNK-ju.\\\\
Sledi:
\[
    P(M_p \lvert \neg S) = P(M_p \lvert M_t)P(M_t \lvert \neg S) + P(M_p \lvert \neg M_t)P(\neg M_t \lvert \neg S).
\]\\
Sedaj je $P(M_t \lvert \neg S)$ enako $f$ in zato $P(\neg M_t \lvert \neg S)$ enako $1-f$. $P(M_p \lvert \neg M_t)$ opisuje verjetnost lažno
pozitivnih rezultatov laboratorija(oznaka $FP$) in $P(M_p \lvert M_t)$ verjetnost resničnih pozitivnih rezultatov laboratorija(oznaka $FN$).
Sledi:
\[
    P(M \lvert \neg S) = [(1 - FN) \times f] + [FP \times (1 - f)].
\]
Formula pokaže, da za pravilno oceno verjetnosti $P(M_p \lvert \neg S)$ potrebujemo statistično oceno pogostosti profila DNK in stopnje napak
laboratorijskih analiz, ki pa so redko na voljo.\\\\
Druga poenostavitev je, da predpostavimo, da je $P(M_p \lvert S) = 1$, pri čemer ni upoštevana možnost lažnega negativnega rezultata. Kot zgoraj, 
imamo:
\[
    P(M_p \lvert S) = P(M_p \lvert M_t)P(M_t \lvert S) + P(M_p \lvert \neg M_t)P(\neg M_t \lvert S).
\]\\
Če je $P(M_p \lvert S) = 1$, je $P(\neg M_p \lvert S) = 0$ in $P(M_p \lvert S) = 1 - FN$. Potem sledi, da je:
\[
    \frac{P(M_p \lvert S)}{P(M_p \lvert \neg S)} = \frac{1 - FN}{[(1 - FN) \times f] + [FN \times (1 - f)]}.
\]\\\\
Za predstavo, kako stopnje napak vplivajo na razmerje verjetnosti, predpostavim, da je pogostost profila DNK 1 proti milijardi. Predpostavim 
tudi, da sta stopnji lažno poztivnih in negativnih laboratorijskih rezuktatov(tj. FP in FN) enako $0,01$. Če je razmerje verjetnosti enako 
$\frac{1}{f}$, je milijarda. S formulo pa dobimo:
\[
    \frac{P(M_p \lvert S)}{P(M_p \lvert \neg S)} = \frac{1 - 0,01}{[(1 - 0,01) \times 0,000000001] + [0,01 \times (1 - 0,000000001)]} \approx 99.
\]\\
Relativno majhne stopnje napak lahko bistveno zmanjšajo dokazno vrednost DNK dokazov, saj močno zmanjšajo razmerje verjetnosti; v našem primeru 
smo iz milijarde prišli na pribljižno 100. Vpliv stopnje laboratorijskih napak kaže, da ne glede na to, kako nizka se izkaže pogostost profila, 
bo ta relativno nepomembna, če pogostosti ne spremlja ocena stopnje laboratorijskih napak. Bayesovo pravilo nam omogoča, da ta vidik upoštevamo.\\\\
Ker profili DNK predstavlja del naše genetske zasnove in imajo ljudje, ki so v sorodu, večjo verjetnost, da bodo imeli enak profil DNK, kot ljudje, 
ki niso v sorodu morajo forenzični strokovnjaki svoje izjave vedno opredeliti z navedbo, da njihove ocene pogostosti veljajo za populacijo nepovezanih 
posameznikov. To spremenljivost pogostosti profila lahko v Bayesovem okviru upoštevamo na dva načina: s spremembo predhodne verjetnosti in s 
spremembo pogostosti profila. Izvedli bi lahko tudi različne izračune: enega za populacijo nepovezanih posameznikov in drugega za populacijo 
sorodnih posameznikov.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Primer - Taksi podjetja}
Za lažje razumevanje Bayesovega pravila si poglejmo primer. \\

Obstajata dve taksi podjetji, Zeleni Taksi in Modri taksi, katerih vozila so pobarvana zeleno oziroma modro. Podjetje Zeleni taksi pokriva 
85 odstotokov trga, podjetje Modri taksi pa preostanek. Predpostavimo še, da v okolici ni drugih taksi podjetij. V meglenem dnevu taksi trči 
v mimoidočega pešca in ga poškoduje, vendar odpelje s kraja nesreče. Priča nesreče poroča, da je bilo vozilo modre barve. Priča ima prav le 
v 80 odstotokih primerov, kar pomeni, da je njegova zanesljivost enaka $0,8$. Kolikšna je verjetnost, da je bil taksi, ki je povzročil nesrečo, 
modre barve glede na poročilo priče? \\

Vpeljimo oznake:\\
$Z$ \dots hipoteza, da je bil taksi zelen, \\
$M$ \dots hipoteza, da je bil taksi moder, \\
$W_m$ \dots dokaz, t.j. poročanje priče, da je bil taksi moder. \\ \\
Problem je določiti pogojno verjetnost hipoteze $M$, ob pogoju, da je dokaz $W_m$ resničen, torej $P(M \lvert W_m)$. \\

Za uporabo Bayesovega pravila potrebujemo tri elemente: verjetnost dokazov glede na hipotezo, verjetnost dokazov in verjetnost hipoteze. Podjetje 
Zeleni taksi pokriva 85 odstotkov trga, zato je verjetnost $P(Z)=0,85$. Po definiciji verjetnosti, je potem $P(M)=1-P(Z)=0,15$. Vemo tudi, da ima 
priča v 80 odstotkih primerov prav, torej $P(W_m \lvert M) = 0,8$ in $P(W_m \lvert Z) = 0,2$. Izračunajmo še verjetnost dokaza $P(W_m)$:\\
\[P(W_m) = P(W_m \lvert B)P(M) + P(W_m \lvert Z)P(Z)= 0,8 \times 0,15 + 0,2 \times 0,85 = 0,29.\]\\

Sedaj lahko uporabimo Bayesovo pravilo:
\[P(M \lvert W_m)= \frac{P(W_m \lvert M)P(M)}{P(W_m \lvert M)P(M) + P(W_m \lvert Z)P(Z)} = \frac{0,8 \times 0,15}{0,29} = \frac{12}{29} \approx 0,41.\] \\

Verjetnost, da je bil taksi glede na pričanje dejansko modre barve, je precej majhna, tudi če ima priča v 80 odstotokih primerov prav. Razlog za to je, 
da je verjetnost $M$, ne glede na dokaze, majhna ($P(M)=0,15$). Spodnja tabela kaže, da lahko s spreminjanjem verjetnosti $M$ dobimo različne pogojne 
verjetnosti $P(M \lvert W_m)$, pri čemer je zanesljivost priče nespremenjena:

\begin{table}[h!]
\centering
\begin{tabular}{c c c c} 
\hline
$P(M)$ & $P(Z)$ & $P(W_m \lvert M)$ & $P(M \lvert W_m)$ \\ 
\hline
0,15 & 0,85 & 0,8 & 0,41 \\
0,25 & 0,75 & 0,8 & 0,57 \\
0,35 & 0,65 & 0,8 & 0,68 \\
0,45 & 0,55 & 0,8 & 0,76 \\
0,50 & 0,50 & 0,8 & 0,80 \\
0,55 & 0,45 & 0,8 & 0,83 \\
0,65 & 0,35 & 0,8 & 0,88 \\
0,75 & 0,25 & 0,8 & 0,92 \\
0,85 & 0,15 & 0,8 & 0,95 \\
\hline
\end{tabular} \vspace{3mm}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Bayesova omrežja}
Bayesova omrežja kot taka pomagajo določiti ustrezne verjetnostne formule, ne da bi prikazali njihovo polno algebrsko obliko, in omogočajo 
skoraj popolno avtomatizacijo potrebnih verjetnostnih izračunov. 
\begin{definicija}
    Bayesovo omrežje(BN) je verjetnostni grafični model, ki predstavlja množico spremenljivk in njihovih pogojnih odvisnosti prek usmerjenega 
    acikličnega grafa.
\end{definicija}
Vozlišča teh usmerjenih acikličnih grafov predstavljajo spremenljivke (lahko so opazovane količine, latentne spremenljivke, neznani parametri 
ali hipoteze). Povezave predstavljajo pogojne odvisnosti; vozlišča, ki niso povezana, predstavljajo spremenljivke, ki so pogojno neodvisne 
druga od druge. Vsako vozlišče je povezano z verjetnostno funkcijo, ki kot vhodni podatek sprejme določen niz vrednosti za nadrejene spremenljivke 
vozlišča in kot izhodni podatek poda verjetnost (ali verjetnostno porazdelitev, če je primerno) spremenljivke, ki jo predstavlja vozlišče. Puščice 
predstavljajo razmerja pomembnosti, ki jih strokovnjak predvideva v okviru zadevnega problema sklepanja. Usmerjena povezava od vozlišča A do 
vozlišča B pomeni, da ima A neposreden vpliv na B. Povezave med vozlišči se včasih razlagajo kot vzročne povezave, vendar opredelitev Bayesovih 
omrežij ne zahteva, da povezave predstavljajo vzročni vpliv. Na splošno velja, da povezave v omrežju predstavljajo verjetnostna razmerja 
pomembnosti. Značilnost Bayesovih omrežij je vključitev verjetnosti v obliki tabel, povezanih z vsakim vozliščem. To omogoča razlago narave in 
moči odnosov med različnimi grafičnimi komponentami omrežja. Tabele verjetnosti vozlišč lahko torej obravnavamo kot sredstvo za povezovanje 
modela s podatki.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Gradnja Bayesovih omrežij}
Obstajajo tri osnovne vrste povezav med vozlišči: zaporedne, razhajajoče se in združevalne povezave. Te so prikazane na sliki 1. \\
\begin{figure}[!ht]\label{fig:slika2}
    \centering
    \includegraphics[scale=0.60]{slika5.png}
    \caption{Osnovne povezave v Bayesovih omrežjih:(a)zaporedna, (b)združevalna in (c)razhajajoča povezava.}\vspace{2mm}
\end{figure}
Zaporedna povezava je primerna, kadar presodimo, da poznavanje resničnega stanja $A$ zagotavlja relevantno informacijo o pojavu $B$ in poznavanje 
resničnega stanja $B$ posledično zagotavlja relevantno informacijo o $C$, vendar ko je znano resnično stanje $B$, poznavanje stanja $A$ ne 
zagotavlja več relevantne informacije o $C$. $A$ vpliva na $C$ preko $B$, vendar samo $B$ neposredno vpliva na $C$. Če je vrednost $B$ znana, 
potem sta $A$ in $C$ verjetnostno neodvisna, tj. $P(C \lvert A, B) = P(C \lvert B)$.\\
\textit{Primer zaporedne povezave:} naj bodo hipoteze\\
$A \dots$ PoI je storilec kaznivega dejanja;\\
$B \dots$ Krvni madež, najden na kraju kaznivega dejanja, je od PoI;
$c \dots$ Vzorec krvi poškodovanca in krvni madež s kraja kaznivega dejanja imata enak profil DNK. \\
Potem je $A$ relevanten za $B$ in $B$ za $C$, vendar je lahko vzrok za prisotnost krvi glede na $B$ drugačen od $A$.\\\\
Pri združevalni povezavi za tri vozlišča $A$, $B$, $C$ sta $A$ in $B$ verjetnostno neodvisna, razen če je znana vrednost $C$ ali da sta $A$ in $B$ 
pogojno odvisna glede na vrednost $C$. Tako je $P(AB) = P(A) P(B)$, vendar $P(AB \lvert C) \ne P(A \lvert C) P(B \lvert C)$.\\
\textit{Primer združevalne povezave s tremi vozlišči $A$, $B$, $C$:} naj bo\\
$A \dots$ PoI je storilec kaznivega dejanja;\\
$B \dots$ Krvni madež, najden na kraju kaznivega dejanja, je od storilca kaznivega dejanja.\\ 
Če vemo, da se je eden od teh dogodkov zgodil, ne moremo pridobiti informacij o dogodku drugega, če pa je $C$ (krvni madež, najden na kraju 
kaznivega dejanja, izvira od PoI) resničen, potem $A$ in $B$ postaneta povezana.\\\\
Pri razhajajoči se povezavi $A$ ločuje $B$ od $C$. Če je vrednost $A$ znana, potem sta $B$ in $C$ verjetnostno neodvisna, tj. 
$P(B \lvert A, C) = P(B \lvert A)$ in $P(C \lvert A, B) = P(C \lvert A)$.\\\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Uporaba Bayesovih omrežij na sodišču}
Bayesova omrežja, ki temeljijo na Bayesovi teoriji in teoriji grafov, ponujajo forenzičnim znanstvenikom več prefinjenih možnosti. Tem metodam 
se daje poseben poudarek, kadar je treba med konkurenčnimi hipotezami izbrati najverjetnejšo, izbira pa mora biti podprta z znanstveno utemeljeno 
argumentacijo. Primerna so za analizo dogodka, ki se je zgodil, in napovedovanje verjetnosti, da je k temu prispeval kateri koli od več možnih 
znanih vzrokov. Prednosti Bayesovih mrež se najbolj izrazito pokažejo na zapletenih področjih z več spremenljivkami. Kriminalistične aplikacije 
Bayesovih omrežij segajo od prepoznavanja storilcev, posameznih in kompleksnih konfiguracij različnih vrst sledi ter problemov sklepanja, ki 
vključujejo rezultate analiz DNK.\\
Ti grafični modeli verjetnosti bistveno izboljšajo vrednotenje verjetnostnih razmerij, ki se uporabljajo za ocenjevanje znanstvenih dokazov. 
Omogočajo, da se lotimo kompleksnejših verjetnostnih analiz, kot bi bilo to mogoče s tradicionalnimi pristopi. \\\\
Struktura BN v pravnem kontekstu je dovzetna za napačne predpostavke in napake v procesu ustvarjanja. Izbira vozlišč za dokaze je lahko 
pristranska glede na to, kakšna vrsta argumenta je predstavljena. Argumenti obrambe ali tožilstva lahko na primer poudarjajo nasprotne sklepe 
in zato vključujejo le podskupino dokazov. Če se za izdelavo ne uporablja dosleden okvir, lahko BN, ki jih oblikujejo različne stranke za en 
primer, kažejo različne rezultate. Pri oblikovanju BN za pravno sklepanje je ključnega pomena, da se oblikuje omrežje, ki je razumljivo poroti 
in sodniku.\\\\
Prikaz BN se mora ujemati z intuitivnim pripisovanjem vzročno-posledičnih povezav med končno hipotezo, kot je "Obtoženec je kriv.", podhipotezo 
"Obtoženec je bil na kraju zločina." in dokazi primera. Poleg težav, ki se pojavijo med postopkom strukturiranja, je problematično tudi sklepanje 
iz omrežja, če se izvaja ob napačnih predpostavkah. Verjetnosti, tudi če temeljijo na strokovni presoji, so lahko pristranske zaradi dejavnikov 
motenj v postopku pridobivanja podatkov. Metode za sklepanje morajo zato zagotoviti, da se verjetnosti omrežij ne razlagajo napačno kot dejstva in 
da se izpostavi dejavnik negotovosti. Primerjati morajo verjetnosti za nasprotujoče si hipoteze in morajo zagotoviti okvir za pravnike, da iz 
mreže sklepajo na argumente.\\\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Primer uporabe Bayesovega omrežja}

\end{document}

%https://en.wikipedia.org/wiki/Bayesian_network